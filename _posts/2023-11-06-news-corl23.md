---
layout: post
categories: news
date: 2023-11-06 22:21:59 +00:00
title:  "2 papers and 2 workshop works presented at CoRL'23"
titleurl: https://openreview.net/forum?id=Eal_lL08v_l
important: "true"
highlight: "" #ffffd0"
summary: 'I did not attend CoRL this year but check out some of our recent work presented by colleagues at the main conference:
<br><br>
1. HomeRobot: Open-Vocabulary Mobile Manipulation 
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">The future of robot butlers starts with mobile manipulation.<br>Weâ€™re announcing the NeurIPS 2023 Open-Vocabulary Mobile Manipulation Challenge!<br>- Full robot stack âœ…<br>- Parallel sim and real evaluation âœ…<br>- No robot required âœ…ðŸ‘€<a href="https://t.co/mggAbRhrLP">https://t.co/mggAbRhrLP</a> <a href="https://t.co/Wartsmkyyl">pic.twitter.com/Wartsmkyyl</a></p>&mdash; Chris Paxton (@chris_j_paxton) <a href="https://twitter.com/chris_j_paxton/status/1671543418286141440?ref_src=twsrc%5Etfw">June 21, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
2. Spatial-Language Attention Policies for Efficient Robot Learning (SLAP) <blockquote class="twitter-tweet"><p lang="en" dir="ltr">Excited that our work on SLAP will be appearing at CoRL 2023 <a href="https://twitter.com/corl_conf?ref_src=twsrc%5Etfw">@corl_conf</a> <br>See you there and looking forward to chatting about it!<br>Work with <a href="https://twitter.com/chris_j_paxton?ref_src=twsrc%5Etfw">@chris_j_paxton</a> <a href="https://twitter.com/XiaohanZhang220?ref_src=twsrc%5Etfw">@XiaohanZhang220</a> <a href="https://twitter.com/jdvakil?ref_src=twsrc%5Etfw">@jdvakil</a> <a href="https://twitter.com/ybisk?ref_src=twsrc%5Etfw">@ybisk</a> <a href="https://twitter.com/viddivj?ref_src=twsrc%5Etfw">@viddivj</a> Sam Powers. <a href="https://t.co/CU30b3whgS">https://t.co/CU30b3whgS</a></p>&mdash; Priyam Parashar (@Priyam8Parashar) <a href="https://twitter.com/Priyam8Parashar/status/1701294213311103015?ref_src=twsrc%5Etfw">September 11, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>  
<br><br> 

Also, check out some of the work at LangRob and Robot Learning Workshops. 
<br><br> 
3. PromptBook leverages LLMs for generating robot code! More than examples that were used in Code-as-Policies, we explore Instructions, Chain of Thought Prompting and State Estimation. Led by  
Montserrat Gonzalez and Andy Zeng at Google DeepMind Robotics. Here is the paper on
<a href="https://openreview.net/pdf?id=T8AiZj1QdN"> OpenReview</a>.
<br><br> 
4. Open X-Embodiment is a huge robotics data collection effort to enable training of Robotic Foundational Models across multi-embodiments, different tasks, and different lab setups. <blockquote class="twitter-tweet"><p lang="en" dir="ltr">RT-X: generalist AI models lead to 50% improvement over RT-1 and 3x improvement over RT-2, our previous best models. ðŸ”¥ðŸ¥³ðŸ§µ<br><br>Project website: <a href="https://t.co/GAlvFdqwx5">https://t.co/GAlvFdqwx5</a> <a href="https://t.co/Jzy8b2eOjf">pic.twitter.com/Jzy8b2eOjf</a></p>&mdash; Quan Vuong (@QuanVng) <a href="https://twitter.com/QuanVng/status/1709209020341669988?ref_src=twsrc%5Etfw">October 3, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>'
---
